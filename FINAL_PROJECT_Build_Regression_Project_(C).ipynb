{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPokHESLfALVsTgkoZimEcC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliba12/Introduction-to-Deep-Learning-Neural-Networks-with-Keras/blob/main/FINAL_PROJECT_Build_Regression_Project_(C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictors in the data of concrete strength include:\n",
        "1.\tCement\n",
        "2.\tBlast Furnace Slag\n",
        "3.\tFly Ash\n",
        "4.\tWater\n",
        "5.\tSuperplasticizer\n",
        "6.\tCoarse Aggregate\n",
        "7.\tFine Aggregate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V8KqPErK6qfp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VN3mJHQe5smf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "concrete_data.head(10)"
      ],
      "metadata": {
        "id": "q-XVaWw56zSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data.shape"
      ],
      "metadata": {
        "id": "Nuo_4Pc162bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data.describe()"
      ],
      "metadata": {
        "id": "w1L9rvWo7Qut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data.isnull().sum()"
      ],
      "metadata": {
        "id": "8_YYE7DF7TX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data.columns"
      ],
      "metadata": {
        "id": "LDeERy_e7WTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_data_columns = concrete_data.columns\n",
        "\n",
        "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']]\n",
        "# All Columns except Strength\n",
        "target = concrete_data['Strength'] #Strength Cloumn"
      ],
      "metadata": {
        "id": "rQOSUbXo7Zj-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors.head()"
      ],
      "metadata": {
        "id": "aTByAE5r7eKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target.head()"
      ],
      "metadata": {
        "id": "LPPzrBxI7fL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4_Tz7YfX7ly_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# C. Increate the number of epochs"
      ],
      "metadata": {
        "id": "WAn5oHppifoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*    Train and test the model at the same time using the fit-method\n",
        "*   Split (%30) test- train the data for validation\n",
        "*   Train the model for 100 epochs"
      ],
      "metadata": {
        "id": "eGxx8czpyCEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Base Regression Model in Keras with 1 Hidden Layer:\n",
        "Create a function that defines our regression model for us so that we can conveniently call it to create our model:\n",
        "\n",
        "One hidden layer of 10 nodes, and a ReLU activation function Use the adam optimizer and the mean squared error as the loss function"
      ],
      "metadata": {
        "id": "V7i_J9HZ7xSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#num of inputs = num of predictors colums\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "def regression_model_C():\n",
        "    model_C = Sequential()\n",
        "    model_C.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "    model_C.add(Dense(1))\n",
        "\n",
        "    model_C.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model_C\n",
        "\n",
        "#Define model\n",
        "model_C = regression_model_C()"
      ],
      "metadata": {
        "id": "la4V9h9C7qFG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_mean_squared_error =[]\n",
        "for cycle in range(100):\n",
        "\n",
        "  # Randomly split the data into a training set (%70) and a test set (%30):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.3)\n",
        "\n",
        "  #Train and Test the model at the same time\n",
        "  #model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)\n",
        "res_C= model_C.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=100, verbose=0)\n",
        "\n",
        "#Find mean_squared_error as last value in history\n",
        "mean_squared_error = res_C.history['val_loss'][-1]\n",
        "\n",
        "# Add value of mean_squared_error for every cyclein list\n",
        "list_of_mean_squared_error.append(mean_squared_error)\n",
        "print('cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))\n",
        "#print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS5TRx1u8ND9",
        "outputId": "44a3bb60-d8f0-4b3d-f342-059f5c6fe450"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cycle #100: mean_squared_error 74.30422973632812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
        "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls_jxmOTAFyt",
        "outputId": "1e5c3e10-f7e9-49af-de84-fa9673f0a84e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The mean of the mean squared errors: 74.30422973632812\n",
            "The standard deviation of the mean squared errors: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The mean and the standard deviation of the mean squared errors in case C is a little smaller than in case B. But in both cases error is huge. In my opinion it's not a very good idea to compare result of two poor neural networks with one hidden layer only. Number of epoch does not help.**"
      ],
      "metadata": {
        "id": "vR64aJGIARen"
      }
    }
  ]
}